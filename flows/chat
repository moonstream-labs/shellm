#!/bin/bash
# ~/.config/shellm/flows/chat

# Streaming output via bat
batstream() {
	bat --color=always \
		--wrap=character \
		--unbuffered \
		--file-name "LlamaResponse.md" \
		--theme "TwoDark" \
		--tabs=4 \
		--paging=never \
		--style "numbers,grid,header-filename" \
		--pager "less --RAW-CONTROL-CHARS --quit-if-one-screen --mouse"

}

# Interacts with `llm` CLI API, Streams output via `bat`
chat_with_llm() {
	local input="$1"
	llm <<<"$input" -c | batstream
}

# Read initial input
read -r input

# Process initial input
chat_with_llm "$input"

# Main chat loop for continuous interaction with the LLM
while true; do
	read -r input

	if [[ $input == "q" ]]; then
		break
	fi

	chat_with_llm "$input"
done
